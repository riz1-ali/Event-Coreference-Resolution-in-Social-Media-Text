{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from pprint import pprint\n",
    "import jsonpickle\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successfull!!! :D\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler('iEk2lB2S9h6qdi9bG2F3OOfVX','LHOn4yNXL5ggl193syNeYaMs2jHGlw7zwDVLFc2pjVWW9XD5LO')\n",
    "auth.set_access_token('1450808706-r0tIB7jGbOeHbz5EiXkUed2HdnTyNqZFGSZINTL','UCkmKWNSK6EYvk5MTT75GJERl7MPwGOMEXAsjqFnhmlBw')\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "if (not api):\n",
    "    print(\"Authentication failed :(\")\n",
    "else:\n",
    "    print(\"Authentication successfull!!! :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'corpus.txt', \n",
    "    delimiter='\\t', \n",
    "    names=['event_mention_id', 'tweet_id', 'event_instance_id', 'event_mention_trigger', 'timestamp', 'text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = {\n",
    "    'tweet_id':list(),\n",
    "    'text':list()\n",
    "}\n",
    "tweets = []\n",
    "dataset = []\n",
    "tweet_ids = df['tweet_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(tweet_ids), 100)):\n",
    "    statuses = api.statuses_lookup(tweet_ids[i: i + 100])\n",
    "    dataset.append(statuses)\n",
    "    \n",
    "    for idx, status in enumerate(statuses):\n",
    "        tweet = df.iloc[[idx]]\n",
    "        df1['tweet_id'].append(status._json['id'])\n",
    "        df1['text'].append(status._json['text'])\n",
    "    df_prime = pd.DataFrame(df1)\n",
    "    df_prime.to_csv('fetched_tweets.csv')\n",
    "    time.sleep((15 * 60) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizer as tk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(df1)\n",
    "def cleanTweet(tweet):\n",
    "    s = \" \".join(tk.tokenize(tweet[:-1]))\n",
    "    x = re.sub(r'[^\\x00-\\xf3]', '', s)\n",
    "    return x\n",
    "df1['text'] = df1['text'].apply(cleanTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = {\n",
    "    'event_mention_id': list(), \n",
    "    'tweet_id': list(), \n",
    "    'event_instance_id': list(), \n",
    "    'event_mention_trigger': list(), \n",
    "    'timestamp': list(), \n",
    "    'text':list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet_id in df1['tweet_id'].values:\n",
    "    tweet = df[tweet_id == df['tweet_id']]\n",
    "    for key in df_main.keys():\n",
    "        if key != 'text':\n",
    "            df_main[key].append(tweet[key].values[0])\n",
    "    df_main['text'].append(df1[df1['tweet_id'] == tweet_id]['text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.DataFrame(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(line):\n",
    "    line = line.lower()\n",
    "    line = line.replace(\"'''\", \"'\")\n",
    "    line = line.replace(\"isn't\", \"is not\")\n",
    "    line = line.replace(\"wasn't\", \"was not\")\n",
    "    line = line.replace(\"didn't\", \"did not\")\n",
    "    line = line.replace(\"don't\", \"do not\")\n",
    "    line = line.replace(\"dont\", \"do not\")\n",
    "\n",
    "    line = line.replace(\"doesn't\", \"does not\")\n",
    "    line = line.replace(\"doesnt\", \"does not\")\n",
    "\n",
    "    line = line.replace(\"won't\", \"will not\")\n",
    "    line = line.replace(\"wont\", \"will not\")\n",
    "\n",
    "    line = line.replace(\"wouldn't\", \"would not\")\n",
    "    line = line.replace(\"can't\", \"can not\")\n",
    "    line = line.replace(\"cannot\", \"can not\")\n",
    "\n",
    "    line = line.replace(\"hasn't\", \"has not\")\n",
    "    line = line.replace(\"*questioned\", \"questioned\")\n",
    "    line = line.replace(\"targets\", \"target\")\n",
    "    line = line.replace(\"=\", \"\")\n",
    "        \n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['text'] = df_main['text'].apply(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('FinalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\n",
    "    'generated_dataset.txt', \n",
    "    sep='\\t', \n",
    "    names=[\n",
    "        'event_mention_id', \n",
    "        'tweet_id', \n",
    "        'event_instance_id', \n",
    "        'event_mention_trigger', \n",
    "        'timestamp', \n",
    "        'text'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_mention_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>event_instance_id</th>\n",
       "      <th>event_mention_trigger</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>784576649627103233</td>\n",
       "      <td>48</td>\n",
       "      <td>bragging</td>\n",
       "      <td>1475892624657</td>\n",
       "      <td>drools over a 12-year old and rapes a 13-year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>784576649627103233</td>\n",
       "      <td>1514</td>\n",
       "      <td>rapes</td>\n",
       "      <td>1475892624657</td>\n",
       "      <td>drools over a 12-year old and rapes a 13-year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>784579912812400641</td>\n",
       "      <td>17</td>\n",
       "      <td>is under attack</td>\n",
       "      <td>1475893402661</td>\n",
       "      <td>@thehill @wsj @washtimes @foxnews trump is und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>784579912812400641</td>\n",
       "      <td>1495</td>\n",
       "      <td>helping</td>\n",
       "      <td>1475893402661</td>\n",
       "      <td>@thehill @wsj @washtimes @foxnews trump is und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>784581821233242114</td>\n",
       "      <td>53</td>\n",
       "      <td>attack</td>\n",
       "      <td>1475893857664</td>\n",
       "      <td>republicans attack donald trump following emer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>2807</td>\n",
       "      <td>791598375917486081</td>\n",
       "      <td>1097</td>\n",
       "      <td>does not endorse</td>\n",
       "      <td>1477566734662</td>\n",
       "      <td>boingboing : the yale record does not endorse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>2810</td>\n",
       "      <td>791626364486946816</td>\n",
       "      <td>1116</td>\n",
       "      <td>presses</td>\n",
       "      <td>1477573407657</td>\n",
       "      <td>clinton supporter presses trump surrogate on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>2811</td>\n",
       "      <td>791628209997680641</td>\n",
       "      <td>1116</td>\n",
       "      <td>presses</td>\n",
       "      <td>1477573847661</td>\n",
       "      <td>clinton supporter presses trump surrogate on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>2812</td>\n",
       "      <td>791638100149669888</td>\n",
       "      <td>1097</td>\n",
       "      <td>does not endorse</td>\n",
       "      <td>1477576205657</td>\n",
       "      <td>quite funny semantics here . \" the yale record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2813</td>\n",
       "      <td>791642340628627457</td>\n",
       "      <td>1097</td>\n",
       "      <td>did not endorse</td>\n",
       "      <td>1477577216666</td>\n",
       "      <td>this is awesome the editorial board at the yal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1773 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_mention_id            tweet_id  event_instance_id  \\\n",
       "0                    0  784576649627103233                 48   \n",
       "1                    1  784576649627103233               1514   \n",
       "2                    5  784579912812400641                 17   \n",
       "3                    6  784579912812400641               1495   \n",
       "4                    8  784581821233242114                 53   \n",
       "...                ...                 ...                ...   \n",
       "1768              2807  791598375917486081               1097   \n",
       "1769              2810  791626364486946816               1116   \n",
       "1770              2811  791628209997680641               1116   \n",
       "1771              2812  791638100149669888               1097   \n",
       "1772              2813  791642340628627457               1097   \n",
       "\n",
       "     event_mention_trigger      timestamp  \\\n",
       "0                 bragging  1475892624657   \n",
       "1                    rapes  1475892624657   \n",
       "2          is under attack  1475893402661   \n",
       "3                  helping  1475893402661   \n",
       "4                   attack  1475893857664   \n",
       "...                    ...            ...   \n",
       "1768      does not endorse  1477566734662   \n",
       "1769               presses  1477573407657   \n",
       "1770               presses  1477573847661   \n",
       "1771      does not endorse  1477576205657   \n",
       "1772       did not endorse  1477577216666   \n",
       "\n",
       "                                                   text  \n",
       "0     drools over a 12-year old and rapes a 13-year ...  \n",
       "1     drools over a 12-year old and rapes a 13-year ...  \n",
       "2     @thehill @wsj @washtimes @foxnews trump is und...  \n",
       "3     @thehill @wsj @washtimes @foxnews trump is und...  \n",
       "4     republicans attack donald trump following emer...  \n",
       "...                                                 ...  \n",
       "1768  boingboing : the yale record does not endorse ...  \n",
       "1769  clinton supporter presses trump surrogate on s...  \n",
       "1770  clinton supporter presses trump surrogate on s...  \n",
       "1771  quite funny semantics here . \" the yale record...  \n",
       "1772  this is awesome the editorial board at the yal...  \n",
       "\n",
       "[1773 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet_Reader:\n",
    "    def __init__(self, df):\n",
    "        self.dataframe = df\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx in self.dataframe.index:\n",
    "            temp = self.dataframe['text'][idx]\n",
    "            temp = tk.tokenize(temp.lower())\n",
    "            yield temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_tmpfile(\"word2vec.model\")\n",
    "tweets = Tweet_Reader (df_main) # a memory-friendly iterator\n",
    "\n",
    "model = Word2Vec(tweets, size=100, window=5, min_count=1, workers=4, iter=30)\n",
    "model\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchtext.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {}\n",
    "for word, vocab_obj in model.wv.vocab.items():\n",
    "    v[word] = vocab_obj.count\n",
    "v['<unk>'] = 0\n",
    "v['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = Vocab(v, specials=['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f1d338cf3041e6a5bf524475c413b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3784.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizwan/anaconda3/envs/acads/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/rizwan/anaconda3/envs/acads/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "word2vec_vectors = []\n",
    "for token, idx in tqdm(vc.stoi.items()):\n",
    "    if token in model.wv.vocab.keys():\n",
    "        word2vec_vectors.append(torch.FloatTensor(model[token]))\n",
    "    else:\n",
    "        word2vec_vectors.append(torch.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.set_vectors(vc.stoi, word2vec_vectors, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"'s\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b699962f043d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'s\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"'s\""
     ]
    }
   ],
   "source": [
    "vc.stoi[\"'s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_emb = torch.FloatTensor(vc.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding.from_pretrained(pre_trained_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.Tensor([vc.stoi['<pad>']]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3821557 , -0.4972439 , -0.5901334 , -0.08836859, -0.27361524,\n",
       "       -0.48360226,  0.24551167, -0.6968162 ,  0.33877534, -0.5088345 ,\n",
       "        0.09811841, -0.07253633,  0.4954285 , -0.04667998,  0.02213344,\n",
       "        0.15480609,  0.00363866, -0.5061666 , -0.6533979 , -0.9323445 ,\n",
       "       -0.01032262, -0.34816974, -0.36009434,  0.14922507,  0.12657423,\n",
       "        0.56726134, -0.9851585 , -0.12662159, -0.77473825, -0.2708073 ,\n",
       "        0.00707218, -0.71529   , -0.2839096 , -0.30382675, -0.39199585,\n",
       "       -0.5219222 ,  0.34463128, -0.13196824,  0.08685283,  0.13087487,\n",
       "       -0.590358  ,  0.18899724,  0.31627762, -0.01037497,  0.77803135,\n",
       "        0.29710972, -0.07571774, -0.3354809 , -0.5275393 , -0.43512473,\n",
       "        0.18143053, -0.1266352 ,  0.29629534, -0.50368154, -0.12777792,\n",
       "       -0.5524746 , -1.25475   ,  0.13420637,  0.34761652,  0.39997756,\n",
       "       -0.16451469, -0.14968158, -0.2357309 , -0.00163437,  0.1808891 ,\n",
       "       -0.3058456 , -0.01153537, -0.14755237, -0.5672787 , -0.9143825 ,\n",
       "       -0.6972147 ,  0.35427308,  0.09496414,  0.1038864 , -0.03080049,\n",
       "       -1.1134825 , -0.0377878 , -0.14253114, -0.4196568 ,  0.40539932,\n",
       "        0.3990629 ,  0.76333374,  0.33202878, -1.3990529 ,  0.0111807 ,\n",
       "       -0.21747528,  0.45981413,  0.12681319, -0.07141559,  0.3840653 ,\n",
       "        0.2043159 , -0.03647966,  0.09310271,  0.5775322 , -0.01454806,\n",
       "       -0.10297507, -1.1283677 ,  0.54721427,  0.13884468, -0.03215092],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['httpurl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pkl\", 'wb') as f:\n",
    "    pickle.dump(vc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
